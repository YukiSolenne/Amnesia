"""
LM Studio RAGç³»ç»Ÿ - æƒ…æ„Ÿæ•°æ®æ£€ç´¢ä¸é—®ç­”
ä¾èµ–å®‰è£…ï¼špip install chromadb sentence-transformers openai
"""

from __future__ import annotations

import json
from pathlib import Path

import chromadb
from sentence_transformers import SentenceTransformer
from config.model_config import get_model_config
from scripts.openai_client import call_chat_completion


class EmotionRAG:
    def __init__(
        self,
        jsonl_path: str | None = None,
        project_paths: list[str] | str | Path | None = None,
        lm_studio_url: str = "http://localhost:1234/v1",
        embedding_model: str = "moka-ai/m3e-base",
        chunk_size: int = 800,
        chunk_overlap: int = 200,
    ):
        """
        åˆå§‹åŒ–RAGç³»ç»Ÿ

        Args:
            jsonl_path: JSONLæ•°æ®æ–‡ä»¶è·¯å¾„
            project_paths: é¡¹ç›®æ–‡ä»¶æˆ–ç›®å½•åˆ—è¡¨
            lm_studio_url: LM Studio APIåœ°å€
            embedding_model: ä¸­æ–‡å‘é‡åŒ–æ¨¡å‹
        chunk_size: æ–‡æœ¬åˆ†å—å¤§å°
        chunk_overlap: å—é—´é‡å å­—ç¬¦æ•°
        """
        self.model_cfg = get_model_config()

        print("åŠ è½½å‘é‡æ¨¡å‹...")
        self.embedder = SentenceTransformer(embedding_model)

        print("åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
        self.chroma_client = chromadb.Client()
        self.collection = self.chroma_client.create_collection(
            name="emotion_data", metadata={"hnsw:space": "cosine"}
        )

        if jsonl_path:
            print("åŠ è½½å¹¶å‘é‡åŒ– JSONL æ•°æ®...")
            self.load_data(jsonl_path)
        if project_paths:
            print("åŠ è½½å¹¶å‘é‡åŒ–é¡¹ç›®æ–‡ä»¶...")
            self.load_project_files(project_paths, chunk_size, chunk_overlap)
        print(f"âœ…ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼å…±åŠ è½½ {self.collection.count()} æ¡æ•°æ®")

    def load_data(self, jsonl_path: str):
        """åŠ è½½JSONLæ•°æ®å¹¶å»ºç«‹ç´¢å¼•"""
        with open(jsonl_path, "r", encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue

                last_brace = line.rfind("}")
                json_str = line[: last_brace + 1] if last_brace != -1 else line

                try:
                    item = json.loads(json_str)
                except json.JSONDecodeError as e:
                    print(f"è­¦å‘Šï¼šè·³è¿‡ç¬¬{line_num}è¡Œï¼ŒJSONè§£æå¤±è´¥: {e}")
                    continue

                search_text = self._build_search_text(item)
                embedding = self.embedder.encode(search_text).tolist()

                spectrum = item.get("spectrum", {})
                self.collection.add(
                    embeddings=[embedding],
                    documents=[search_text],
                    metadatas=[
                        {
                            "source": "jsonl",
                            "raw_text": item.get("raw_text", ""),
                            "summary": item.get("summary", ""),
                            "keywords": json.dumps(
                                item.get("keywords", []), ensure_ascii=False
                            ),
                            "valence": spectrum.get("valence", 0.0),
                            "arousal": spectrum.get("arousal", 0.0),
                            "tones": json.dumps(
                                spectrum.get("tones", []), ensure_ascii=False
                            ),
                            "metaphor_domain": item.get("metaphor_domain", ""),
                        }
                    ],
                    ids=[item["id"]],
                )

    def load_project_files(
        self,
        paths: list[str] | str | Path,
        chunk_size: int = 800,
        chunk_overlap: int = 200,
        exts: tuple[str, ...] = (".md", ".txt", ".log", ".rst"),
    ):
        """éå†é¡¹ç›®æ–‡ä»¶å¹¶åˆ†å—ç´¢å¼•"""
        if isinstance(paths, (str, Path)):
            paths = [paths]

        for p in paths:
            p = Path(p)
            files = [p] if p.is_file() else p.rglob("*")
            for file in files:
                if not file.is_file() or file.suffix.lower() not in exts:
                    continue
                text = file.read_text(encoding="utf-8", errors="ignore")
                for i, chunk in enumerate(
                    self._split_text(text, chunk_size, chunk_overlap)
                ):
                    embedding = self.embedder.encode(chunk).tolist()
                    self.collection.add(
                        embeddings=[embedding],
                        documents=[chunk],
                        metadatas=[{"source": "project", "path": str(file), "chunk": i}],
                        ids=[f"{file}-{i}"],
                    )

    def _split_text(self, text: str, chunk_size: int, chunk_overlap: int):
        """ç®€å•åˆ†å—ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿"""
        start = 0
        n = len(text)
        while start < n:
            end = min(start + chunk_size, n)
            yield text[start:end]
            if end == n:
                break
            start = end - chunk_overlap if end - chunk_overlap > start else end

    def _build_search_text(self, item):
        """æ„é€ ç”¨äºæ£€ç´¢çš„æ–‡æœ¬"""
        spectrum = item.get("spectrum", {})
        keywords = item.get("keywords", [])
        tones = spectrum.get("tones", [])
        valence = spectrum.get("valence", 0.0)
        arousal = spectrum.get("arousal", 0.0)

        return (
            f"åŸæ–‡ï¼š{item.get('raw_text', '')}\n"
            f"æ‘˜è¦ï¼š{item.get('summary', '')}\n"
            f"å…³é”®è¯ï¼š{', '.join(keywords) if keywords else ''}\n"
            f"æƒ…æ„Ÿç»´åº¦ï¼šæ•ˆä»·{valence}, å”¤é†’åº¦{arousal}\n"
            f"æƒ…æ„Ÿè‰²è°ƒï¼š{', '.join(tones) if tones else ''}\n"
            f"éšå–»åŸŸï¼š{item.get('metaphor_domain', '')}"
        )

    def chat_completion(self, messages, temperature=0.7, max_tokens=None):
        """è°ƒç”¨ .env ä¸­é…ç½®çš„ OpenAI-Compatible API è·å–å›å¤"""
        cfg = self.model_cfg
        resp = call_chat_completion(
            cfg["base_url"],
            cfg["api_key"],
            cfg["name"],
            messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        return resp["choices"][0]["message"]["content"]

    def search(self, query, top_k=3, valence_filter=None):
        """
        è¯­ä¹‰æ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            valence_filter: æƒ…æ„Ÿæ•ˆä»·è¿‡æ»¤ (min, max)
        """
        query_embedding = self.embedder.encode(query).tolist()

        where_filter = None
        if valence_filter:
            where_filter = {
                "$and": [
                    {"valence": {"$gte": valence_filter[0]}},
                    {"valence": {"$lte": valence_filter[1]}},
                ]
            }

        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=where_filter,
        )

        return results

    def query(self, question, top_k=3, temperature=0.7):
        """
        RAGé—®ç­”

        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡
            temperature: LLMç”Ÿæˆæ¸©åº¦
        """
        print("\nğŸ” æ£€ç´¢ç›¸å…³æ•°æ®...")
        results = self.search(question, top_k=top_k)

        context_parts = []
        for i, (doc, metadata) in enumerate(
            zip(results["documents"][0], results["metadatas"][0]), 1
        ):
            context_parts.append(
                f"\nã€æ•°æ®{i}ã€‘\næ¥æº: {metadata.get('source', 'unknown')} {metadata.get('path', '')}\n{doc}\n"
            )

        context = "\n".join(context_parts)

        prompt = (
            "ä½ æ˜¯ä¸€ä¸ªæƒ…æ„Ÿåˆ†æä¸“å®¶ã€‚åŸºäºä»¥ä¸‹æƒ…æ„Ÿæ•°æ®åº“ä¸­çš„å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n"
            f"æ•°æ®åº“å†…å®¹ï¼š\n{context}\n\n"
            f"ç”¨æˆ·é—®é¢˜ï¼š{question}\n\n"
            "è¯·ç»“åˆæ•°æ®ä¸­çš„åŸæ–‡ã€æƒ…æ„Ÿç»´åº¦ï¼ˆæ•ˆä»·/å”¤é†’åº¦ï¼‰ã€å…³é”®è¯ã€æƒ…æ„Ÿè‰²è°ƒå’Œéšå–»åŸŸè¿›è¡Œæ·±å…¥åˆ†æï¼Œ"
            "ç”¨ç®€æ´è¦ç‚¹å›ç­”ã€‚"
        )

        print("ğŸ¤– ç”Ÿæˆå›å¤...")
        content = self.chat_completion(
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ç†è§£å’Œåˆ†æäººç±»æƒ…æ„Ÿè¡¨è¾¾ï¼Œå›ç­”è¦ç®€æ´ã€‚",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=temperature,
        )

        print("\nğŸ’¬ å›å¤ï¼š")
        print(content)
        print("\n")
        return content

    def analyze_emotion_pattern(self, emotion_type):
        """åˆ†æç‰¹å®šæƒ…æ„Ÿæ¨¡å¼"""
        query_map = {
            "æ¶ˆæ": "æ‰¾å‡ºæœ€æ¶ˆææ‚²ä¼¤çš„æƒ…æ„Ÿè¡¨è¾¾",
            "ç§¯æ": "æ‰¾å‡ºæœ€ç§¯æå¿«ä¹çš„æƒ…æ„Ÿè¡¨è¾¾",
            "æ¿€çƒˆ": "æ‰¾å‡ºæƒ…ç»ªæœ€å¼ºçƒˆæ¿€åŠ¨çš„è¡¨è¾¾",
            "å¹³é™": "æ‰¾å‡ºæƒ…ç»ªæœ€å¹³é™æ·¡å®šçš„è¡¨è¾¾",
        }

        if emotion_type in query_map:
            return self.query(query_map[emotion_type], top_k=5)
        else:
            return "ä¸æ”¯æŒçš„æƒ…æ„Ÿç±»å‹ï¼Œè¯·é€‰æ‹©ï¼šæ¶ˆæã€ç§¯æã€æ¿€çƒˆã€å¹³é™"


def main():
    """ä½¿ç”¨ç¤ºä¾‹"""
    print("=" * 60)
    print("æƒ…æ„Ÿæ•°æ®RAGç³»ç»Ÿ - åŸºäºLM Studio")
    print("=" * 60)

    # åˆå§‹åŒ–ç³»ç»Ÿï¼ˆå°†è·¯å¾„æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„ï¼‰
    rag = EmotionRAG(
        jsonl_path="data/cards.jsonl",
        project_paths=["readme.md", "logs", "docs"],
        lm_studio_url="http://localhost:1234/v1",
    )

    # ç¤ºä¾‹æŸ¥è¯¢
    # print("\n" + "=" * 60)
    # print("ç¤ºä¾‹1ï¼šæ£€ç´¢ç‰¹å®šä¸»é¢˜")
    # print("=" * 60)
    # rag.query("é¡¹ç›®ä¸­å…³äºé“å¾·çš„æƒ…æ„Ÿè¡¨è¾¾æœ‰å“ªäº›ï¼Ÿ")

    # print("\n" + "=" * 60)
    # print("ç¤ºä¾‹2ï¼šæƒ…æ„Ÿåˆ†æ")
    # print("=" * 60)
    # rag.query("åˆ†ææ•°æ®ä¸­æœ€æ¶ˆæçš„æƒ…æ„Ÿç‰¹å¾")

    # print("\n" + "=" * 60)
    # print("ç¤ºä¾‹3ï¼šå¯¹æ¯”åˆ†æ")
    # print("=" * 60)
    # rag.query("å¯¹æ¯”åˆ†æé«˜å”¤é†’åº¦å’Œä½å”¤é†’åº¦çš„æƒ…æ„Ÿè¡¨è¾¾æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ")

    # äº¤äº’æ¨¡å¼
    print("\n" + "=" * 60)
    print("è¿›å…¥äº¤äº’æ¨¡å¼ï¼ˆè¾“å…¥'quit'é€€å‡ºï¼‰")
    print("=" * 60)

    while True:
        question = input("\nè¯·è¾“å…¥é—®é¢˜ï¼š").strip()
        if question.lower() in ["quit", "exit", "é€€å‡º"]:
            break
        if question:
            rag.query(question)


if __name__ == "__main__":
    main()
