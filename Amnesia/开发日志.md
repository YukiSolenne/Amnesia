# **开发日志**

2025-9-23 day2

昨天用qwen-7b-chat跑通了之后超兴奋，发小红书广而告之。

今天换了deepseek-r1-distill-qwen-14b，这个模型还挺不错的。

前端报错了。



> *(.venv) PS D:\Amnesia> & d:/Amnesia/.venv/Scripts/python.exe d:/Amnesia/scripts/chat_to_card.py*
> *写下一段要封存的记忆：*
>
> 想念你的心情就像水从瓶子里溢出
>
> Traceback (most recent call last):
> File "d:\Amnesia\scripts\chat_to_card.py", line 166, in <module>
> main()
> File "d:\Amnesia\scripts\chat_to_card.py", line 137, in main
> resp = call_chat_completion(BASE, KEY, MODEL, msg, temperature=0.7, timeout=120)
>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> File "d:\Amnesia\scripts\openai_client.py", line 23, in call_chat_completion    
> with request.urlopen(req, timeout=timeout) as resp:
>     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> File "C:\Users\nagi\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 216, in urlopen
> return opener.open(url, data, timeout)
>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> File "C:\Users\nagi\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 519, in open
> response = self._open(req, data)
>           ^^^^^^^^^^^^^^^^^^^^^
> File "C:\Users\nagi\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 536, in _open
> result = self._call_chain(self.handle_open, protocol, protocol +
>         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> File "C:\Users\nagi\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 496, in _call_chain
> result = func(*args)
>         ^^^^^^^^^^^
> File "C:\Users\nagi\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 1377, in http_open
> return self.do_open(http.client.HTTPConnection, req)
>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> File "C:\Users\nagi\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 1352, in do_open
> r = h.getresponse()
>    ^^^^^^^^^^^^^^^
> File "C:\Users\nagi\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1390, in getresponse
> response.begin()
> File "C:\Users\nagi\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 325, in begin
> version, status, reason = self._read_status()
>                          ^^^^^^^^^^^^^^^^^^^
> File "C:\Users\nagi\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 286, in _read_status
> line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> File "C:\Users\nagi\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto
> return self._sock.recv_into(b)
>       ^^^^^^^^^^^^^^^^^^^^^^^
> TimeoutError: timed out

然后这是LM Studio后端（这么称呼真的没错吗）

> "content": "<think>
>
> 首先，我需要分析用户的输入：“想念你的心情就像水从瓶子里溢出”。这句话表达了强烈的思念之情，用“水溢出”这个比喻来形象地描述情感的无法抑制。
>
> 
>
> 接下来，我要构建draft对象。总结部分要简洁中立，所以我会写“用户以水流溢出为喻，表达深切的思念之情”。关键词包括“想念”、“水”和“瓶子”。
>
> 
>
> 然后是情感光谱部分。由于思念通常是积极的情感，但带有一定的悲伤色彩，所以我将valence设为0.6，表示较为正面但略带负面的情绪。唤醒度设置为0.8，因为这种情绪往往让人感到激动或投入。tones选择“怀旧”和“深情”，符合思念的主题。
>
> 
>
> 接下来是隐喻域的选择。用户使用了水溢出的比喻，这与“暴风雪”这个选项不符，更接近于液体流动的情况，但提供的选项中没有完全匹配的。考虑到情感的强烈和无法抑制，我可能需要选择最接近的一个，或者可能重新审视选项是否遗漏了其他可能性。假设只能从给定的四个选项中选，“焰火花”可能不太合适，而“暴风雪”虽然强度大，但更偏向于情绪的爆发，所以这里可能更适合选择“水”相关的隐喻，不过在选项中并没有，因此可能需要调整或者说明。
>
> 
>
> 最后，metaphor_seed设为1024，保持与",

很棒的思考，比qwen7b要棒多了。但是好像因为话太多被截断了

![image-20250923122938973](C:\Users\nagi\AppData\Roaming\Typora\typora-user-images\image-20250923122938973.png)

可恶，我的C盘飘红了。

![image-20250923143638664](C:\Users\nagi\AppData\Roaming\Typora\typora-user-images\image-20250923143638664.png) ![image-20250923143714913](C:\Users\nagi\AppData\Roaming\Typora\typora-user-images\image-20250923143714913.png)

deepseek就是聪明。

修改了一下格式，jsonl里面还是没能看见thinking内容，但是后端能够很清楚地看见。呈现得很清晰。

2025.9.29

因为实在忍受不了thinking的速度和输出方式，最终还是买了deepseek的api，先充值10块试试水哈哈。

（其实后面又买了很多…………~~）

| PARAM      | VALUE                      |
| ---------- | -------------------------- |
| base_url * | `https://api.deepseek.com` |
| api_key    | apply for an [API key]     |

deepseek的api连通了。一开始连不通是因为.env文件没有同步和文件里更新。更新完之后，能输出回复。回复内容好诡异，还是deepseek一贯的切除前额叶的Ne拉满的回复。

![image-20250929111311040](C:\Users\nagi\AppData\Roaming\Typora\typora-user-images\image-20250929111311040.png)

不过好在回复还挺快的。

请求了两次，花了快5000token，主要是system prompt的token数量就有1200，返回的又是一长串json。

> {"id": "4c62cc60-55a0-4806-ab8f-977d9138f917", "created_at": 1759115476494, "raw_text": "上课好无聊，想吃饭", "summary": "用户表达上课时的无聊和对吃饭的期待。", "keywords": ["上课", "无聊", "吃饭", "期待"], "spectrum": {"valence": -0.2, "arousal": 0.4, "tones": ["迟滞", "灰尘", "冷光", "错过"]}, "thinking": "用户描述的上课无聊属于低愉悦状态，对吃饭的期待带来中等唤醒。联想到教室里的粉笔灰、缓慢移动的时钟指针，与等待吃饭的急切形成对比。选择'dust'域表现课堂的沉闷，用'钟声'和'飘向食堂'暗示时间流逝与期待。", "metaphor_domain": "dust", "metaphor_seed": 3712}

seed是什么？

2025.9.30

实在是太想用claude了，在openrouter买了api。

![image-20250930155911568](C:\Users\nagi\AppData\Roaming\Typora\typora-user-images\image-20250930155911568.png)

2025.10.9

时光如白驹过隙……我什么也没干……有点不清楚自己为什么要做这个了，没有深入思考过为什么。

现在想做的：1、用google colab微调一个模型 2、做一个小数据集 3、尝试构建RAG 4、整明白dify

感觉无论是哪个都不容易

我的cursor正在努力工作，而我在上课摸鱼……呵呵

发现了一些有趣的东西。可以比较一下

claude3.7sonnet：{"id": "abc8fe47-a885-4919-aeaa-5f6004f9f9a1", "created_at": 1760068208407, "raw_text": "", "summary": "用户描述了对一个名为**的人的复杂情感，包括梦境、矛盾的感受、过去的喜欢以及对方在自己心中的形象。情感既有怀念又有不甘，既想亲近又有质疑。", "keywords": ["梦境", "喜欢", "矛盾", "悸动", "二分", "抓住", "不甘心"], "spectrum": {"valence": -0.2, "arousal": 0.7, "tones": ["思念", "无以名状", "悬着", "频闪", "回退键"]}, "thinking": "文本表达了强烈的情感冲突和不确定性。valence略偏负面(-0.2)是因为尽管有'喜欢'和'悸动'等正面情感，但整体笼罩着未能触及、不甘心的失落感。arousal较高(0.7)体现在梦境追寻、情感波动和内心冲突的强烈程度。文本中的'抓住'、'不甘心'、'二分'等词表明情绪处于高度活跃状态。", "metaphor_domain": "失真的讯号", "metaphor_seed": 1729} 

这个好像是4o：{"id": "14fb4117-ba1f-4b92-a7c8-618003662064", "created_at": 1760068346741, "raw_text": "", "summary": "用户描述了对一个名为**的人的复杂情感，包括梦见对方、被对方吸引又排斥、渴望亲近又感到距离感的矛盾心理。", "keywords": ["梦境", "**", "矛盾情感", "喜欢", "悸动", "二分", "抓住", "魅魔", "调教"], "spectrum": {"valence": -0.3, "arousal": 0.7, "tones": ["悬着", "雨将落未落", "噪点", "门轴尖叫", "频闪"]}, "thinking": "文本表达了强烈的情感冲突和矛盾。一方面有对'**'的依恋和喜欢('我真的喜欢过你'、'心里还有悸动')，另一方面又有挣扎和不甘('我不甘心')。情感效价偏负(valence=-0.3)因为整体流露出未解的痛苦和困惑多于愉悦。唤醒度较高(arousal=0.7)因为文本充满了强烈的渴望、不安和紧张感，特别是'把你抓住'这样的表述显示了情绪的激烈。文本中的'魅魔'、'调教'等词汇暗示了一种不平等或复杂的关系动态，而'不太完整'的梦境和'不太能触及'的感觉表明了一种持续的心理紧张状态。", "metaphor_domain": "storm", "metaphor_seed": 1792}模型不明

这个是本地的微调小模型：{"id": "330f0895-091c-4868-9abe-ccff97292121", "created_at": 1760068713612, "raw_text": "", "summary": "用户表达了对**的复杂情感，涉及梦、身份认同和亲密关系中的权力与吸引力。", "keywords": ["梦见", "魅魔", "M", "完美主义者", "悸动", "投射"], "spectrum": {"valence": 0.6, "arousal": 0.8, "tones": ["tenderness", "anxiety", "reflection"]}, "thinking": "用户的核心情感是强烈的、矛盾的爱恋。它包含对**的‘魅魔’身份认同，以及对自己作为M的身份和欲望的探索。这是一种高度投入的关系幻想，充满了‘投射’（将自己理想化的特质投向对方）和自我审视。这种状态虽然带着焦虑和不安（担心被发现、被拒绝），但其核心驱动力是强烈的渴望（valence高）。用户的唤醒度很高，因为她正在一个非常私密且充满想象的情境中进行深度探索。", "metaphor_domain": "失真默片", "metaphor_seed": 1024}

deepseek-chat 3.2：{"id": "177785a9-0d55-4f5d-87d3-a8a3ee09507a", "created_at": 1760068857862, "raw_text": "", "summary": "用户表达了对**复杂矛盾的情感，包含梦境中的思念、不甘、愤怒与自我反思。", "keywords": ["梦见", "魅魔", "调教", "不甘心", "丑陋", "光环", "悸动", "二分", "抓住"], "spectrum": {"valence": -0.2, "arousal": 0.7, "tones": ["惊醒", "悬着", "噪点", "紧绷", "乱流"]}, "thinking": "用户情感复杂：valence为负因不甘与愤怒（-0.2），arousal高因强烈矛盾与冲动（0.7），结合梦境、质问与自我怀疑，选择高唤醒负面情感色调。", "metaphor_domain": "storm", "metaphor_seed": 2048}

这个对比真的很值得细品。

---

2025.11.7 笔记

## 在 Dify 里怎么实现？

### ✅ 第一步：建一个「知识库」

1. 在 Dify 主页面点左侧「知识库」（Knowledge Base）
2. 新建一个知识库，比如叫「Emotion Schema」
3. 支持的内容格式：
   - Markdown、TXT、PDF、网页链接都行
   - 推荐你先整理好一批 Markdown 文件，每种情绪一个小节，像这样：

```
# 悸动
- valence: 0.6
- arousal: 0.9
- metaphor: “像雨滴砸进春泥，温柔又倔强。”

# 忧郁
- valence: -0.7
- arousal: 0.4
- metaphor: “像落叶背后的风，没有名字，只留下声音。”

# 响应模版
请你以档案馆员的身份，以哲理性、诗意语言回应此类情绪。不可使用直接安慰语句。
```

------

### ✅ 第二步：在工作流中加上知识库搜索

1. 在“代码执行”节点之后，**插入一个“知识库问答”节点（Knowledge Base QA）**

2. 设置这个节点使用刚才创建的 `Emotion Schema` 知识库

3. 输入可以是：

   ```
   请根据以下内容，查找合适的情绪定义和哲理表达：
   {{ inputs.memory_text }}
   ```

4. 输出变量设为 `kb_response`，或者你喜欢的名字

------

### ✅ 第三步：将知识库检索结果拼进最终 prompt

你可以在 **LLM 节点里这么写 User Prompt**：

```
记忆片段：
{{ inputs.memory_text }}

请参考以下情绪分类和哲理语句：
{{ kb.outputs.kb_response }}

请根据以上内容，用档案馆员的语气回应这段记忆。
```

System Prompt 也可以留一小段：“你是失语图书馆的档案馆员……你会参考知识库中的哲理语句和情绪结构进行回应。”





